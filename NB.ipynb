{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f35162-01c8-420d-b549-0d7fa7385c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0171997-4bb5-4e17-9da4-abe22f0368c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/spam.csv\", encoding=\"latin1\")\n",
    "print(data.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aeaf4ed-ae4d-42e0-af6f-de9f952345db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17870815-5c0b-4cb3-8330-884077bfe3f8",
   "metadata": {},
   "source": [
    "# 1. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5685105-d6be-4131-b80c-378659d0fc88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['v2'], data['v1'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea31045-8b51-4927-b048-d8504ad964b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900,)\n",
      "(1672,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b69ac2-ad3b-4a99-bf7c-74c9111083f7",
   "metadata": {},
   "source": [
    "# 2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e70004-e818-42f4-b130-f5ae9425e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_X = vectorizer.fit_transform(X_train).toarray() # transform from text data to count matrix\n",
    "test_X = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec07fdd8-8260-4986-9add-9d1bbd05bf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eb20701-3db1-445d-a956-6d2b0e3d792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.map({'ham':0,'spam':1})\n",
    "y_test = y_test.map({'ham':0,'spam':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e024c-6b06-4adb-b4d2-b31975d9d134",
   "metadata": {},
   "source": [
    "# 3. Building a NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "552c7724-7f11-4887-bed0-772aeb8a6e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9948717948717949"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(force_alpha=True)\n",
    "# training phase\n",
    "clf.fit(train_X,y_train)\n",
    "clf.score(train_X,y_train) # accuracy of model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3777de4e-8f7b-4890-a23f-37d3158dbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing phase\n",
    "preds = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eddc7d9-f1a2-4b1b-8625-7172b2d14be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada60ed-b326-491e-96ed-fec190360bdb",
   "metadata": {},
   "source": [
    "# 4. Model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94cf958e-04f6-4441-8500-58ceebc48f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9966    0.9830    0.9897      1473\n",
      "           1     0.8858    0.9749    0.9282       199\n",
      "\n",
      "    accuracy                         0.9821      1672\n",
      "   macro avg     0.9412    0.9790    0.9590      1672\n",
      "weighted avg     0.9834    0.9821    0.9824      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(preds, y_test, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5c99e6-694a-464d-9435-f84a1298ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy : 99.48% - test accuracy : 98.21%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22450cb4-e6d4-4193-bab6-3ac04e513fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DEMO_ACCOUNT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DEMO_ACCOUNT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DEMO_ACCOUNT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DEMO_ACCOUNT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c27a2149-fc76-4b68-8243-4510c5a5c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer  \n",
    "stop_words = stopwords.words('english')\n",
    "import re\n",
    "lemma = WordNetLemmatizer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "def pre_process(text):\n",
    "    ## tokenize\n",
    "    tokenized = word_tokenize(text)\n",
    "    ## stopwords removal\n",
    "    stw = [word for word in tokenized if word not in stop_words]\n",
    "    ## lower\n",
    "    lower = [word.lower() for word in stw]\n",
    "    ## lemma\n",
    "    result=[lemma.lemmatize(word) for word in lower]\n",
    "    #### join to make a sentence\n",
    "    results = \" \".join(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40ecf988-ae34-44f1-8c71-44376d4738f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.9951282051282051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9857    0.9938    0.9897      1453\n",
      "           1     0.9565    0.9041    0.9296       219\n",
      "\n",
      "    accuracy                         0.9821      1672\n",
      "   macro avg     0.9711    0.9490    0.9596      1672\n",
      "weighted avg     0.9818    0.9821    0.9818      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.map(pre_process)\n",
    "X_test = X_test.map(pre_process) # preprocess train and test set\n",
    "vectorizer = CountVectorizer() # create count matrix\n",
    "train_X = vectorizer.fit_transform(X_train).toarray() # gồm 2 step: fit (tìm số từ trong dataset), transform (đếm tuần suất xuất hiện)\n",
    "test_X = vectorizer.transform(X_test).toarray()\n",
    "# refit the model\n",
    "clf = MultinomialNB(force_alpha=True)\n",
    "clf.fit(train_X,y_train)\n",
    "print(\"Train acc: \",clf.score(train_X,y_train))\n",
    "preds = clf.predict(test_X)\n",
    "print(classification_report(y_test,preds,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd39b55-59d5-426a-9c39-745f9db871a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
